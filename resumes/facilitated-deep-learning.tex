\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
% Colocar documento em portugues
\usepackage[brazil]{babel}
% Incluir asmmath e outras ferramentas matemátias
\usepackage{mathtools}

% Pacote para demonstração
\usepackage{amsthm}

% Pacote para cores
\usepackage{xcolor}
%\definecolor{pastelyellow}{HTML}{fdfd96} - Definir cor

% Pacote matemático
\usepackage{amsmath}

% Pacote para imagens um ao lado da outra
\usepackage{subfig}

% Pacote e função para espaçamento 1.5
\usepackage{setspace}
\onehalfspacing%

% Pacote para códigos
\usepackage{minted}

% Para representar símbolos dos conjuntos
\usepackage{amsfonts}

% Pacotes para plotar gráficos
\usepackage{tikz, tkz-fct}
\usepackage{pgfplots}
\pgfplotsset{width=8cm,compat=1.9}
\usepackage{pgfplots}
\pgfplotsset{width=10cm,compat=1.9}
\usepackage{tikz-3dplot}

% Pacote para incluir pdf na página
\usepackage{pdfpages}

% Pacore para definições
\newtheorem{theorem}{Definição}

% Gráficos
\usepackage{blindtext}
\usepackage{pgfplots}
\pgfplotsset{compat=1.9}
\usepackage{graphicx}

% Quadradinho$
\usepackage{amssymb}
%Pacote para módulo
\newcommand{\Mod}[1]{\ (\mathrm{mod}\ #1)}
% Definir tamanho das margens
\usepackage[inner=1.25in, outer=1in, top=1in, bottom=1in]{geometry}

% Pacotes para cabeçalho{fancyhdr}
\usepackage{fancyhdr}
\pagestyle{fancy}
\usepackage{lastpage} 
% Pacotes para tabelas que atravessam a página
\usepackage{longtable}
% Pacote para a tabela
\usepackage{float} 

% Define cabeçalho
\lhead{\today}
\chead{}
\rhead{Instituto Federal de Brasília}
% Definir tamanho da linha do cabeçalho
\renewcommand{\headrulewidth}{0.4pt}

\title{Resumo: Facilitated Deep Learning for Image Captioning}
\author{De Matheus Loiola Pinto Curado Silva}
\date{\today}
% Reparar carácter invisível
\DeclareUnicodeCharacter{2212}{-}

\begin{document}

\maketitle

Para saber mais sobre o modelo e menos sobre o planemento e o processo de pesquisa, pule para a seção de arquitetura do modelo e treinamento.

\section*{Introdução}

O objetivo da legendagem de imagens é ajudar em inúmeras aplicações práticas, como engines de busca, recuperação de imagens, entre outros$\ldots$

\section*{Trabalhos relacionados}

Trabalhos iniciais na área proporam métodos de template para extrair atributos das imagens, como objetos, atributos visuais e relações espaciais, e assim gerar palavras usando um modelo \textit{n-gram} para gerar legendas.

Em métodos de Deep Learning, a arquitetura \textit{Encoder-Decoder} foi muito utilizada, e ela consiste em ler uma sentença e convertê-la para uma representação em vetor de tamanho fixo, que é usada inicialmente em uma \textit{hidden layer} para gerar a sequência desejada. Após isso, o vetor de características é levado ao decodificar LSTM para gerar a legenda palavra por palavra. Entretanto, esse método considera a imagem inteira, e não foca em partes específicas da imagem.

Nos modelos de linguagem, RNN tradicionais sofrem com o problema de \textit{vanishing/exploding gradient} em sentenças longas, e por isso, modelos LSTM são utilizados. 

Assim, o modelo proposto pelo autor é um modelo híbrido que considera objetos significantes na imagem pela sua importância, e assim gerar uma legenda mais precisa.

\section*{Metodologia}

O modelo proposto recebe uma imagem, que é processada e enviado ao detector de objetos no formato apropriado. Dessa forma, o detector de objetos retorna uma lista de objetos detectados, que é utilizada em uma heurística para transformar os objetos em um ponto inicial para o legendador, que é um híbrido de um extrator de características e um modelo de linguagem com enriquecimento por atenção, e esse ponto é adicionado em cada iteração no modelo de linguagem. Assim, em conjunto com as características extraídas, o modelo de linguagem é utilizado para gerar a legenda iterativamente.

\section*{Arquitetura do Modelo e Treinamento}

\subsection*{Extrator de características}

O primeiro estágio do artigo foi utilizar um extrator de características já treinado, e o escolhido foi \textit{ResNet50} pre-treinado da ImageNet. O modelo foi utilizado da forma como veio, apenas retiraram o módulo de classificação, para apenas utilizar o vetor de características.

\subsection*{Detector de objetos}

O modelo escolhido para esse estágio foi o \textit{ResNet50} pre-treinado do RetinaNet, e foi treinado do \textit{dataset COCO}, com \textit{mAP} de 0.45, utilizando 70 classes.

\subsection*{Modelo de legendamento}

O modelo precisaria identificar objetos em uma imagem de forma semântica e estrutural, para retornar uma descrição de forma coerente. Assim, dois modelos foram utilizados no estudo do autor: um LSTM de três camadas e um modelo de linguagem com enriquecimento por atenção. 

Além disso, os experimentos foram feitos a partir de variações e legendas originais do \textit{COCO dataset}, e variações do \textit{Flickr30k} para treinamento.

Os dois modelos foram treinados com uma versão pré-processada das legendas, e variando os hiper-parâmetros. O modelo de linguagem com atenção convergiu melhor que o LSTM.%

\section*{Staggering Stages}

Algoritmos de atenção ajudam o modelo a focar em regiões de interesse da imagem, e não olhar ela inteiramente, o que a permite focar nas informações importantes. No começo do modelo de geração de legendas, esse algoritmo não é tão útil, pois existe pouco contexto para se basear. Dessa forma, isso pode ocasionar em erros, visto que, nos estágios avançados do modelo, quando o algoritmo de atenção começa a mostrar seu valor, a informação pode ter convergido anteriormente para um erro, prejudicando todo o processo.

Assim, utilizando um ponto inicial pré-definido, esse problema pode ser evitado, pois o modelo de geração de legendas terá um contexto desde o inicio, e ele servirá como referência para moldar a legenda ao longo das iterações do modelo.

\section*{Resultados}

Os resultados são comparados a partir da \textit{Similaridade entre cosenos}. A partir dele, foi observado que o modelo com esse auxílio da legenda inicial foi superior em $66\%$ das imagens, enquanto o modelo sem auxílio superou ele em apenas $22\%$ das imagens. Dessa forma, o modelo facilitado ofereceu uma melhor perfomance em comparação com os outros modelos.


\end{document}
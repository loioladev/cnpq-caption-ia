                  epoch,             train/loss,  metrics/accuracy_top1,  metrics/accuracy_top5,               val/loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 1.7315,                0.57833,                0.93389,                 2.0264,             0.00023737,             0.00023737,             0.00023737
                      2,                 1.2356,                0.61889,                   0.96,                 1.9361,             0.00046681,             0.00046681,             0.00046681
                      3,                 1.1678,                0.63056,                0.97056,                 1.8953,             0.00068768,             0.00068768,             0.00068768
                      4,                 1.0733,                0.62667,                0.96889,                 1.9113,             0.00067544,             0.00067544,             0.00067544
                      5,                0.96419,                0.66778,                  0.975,                 1.8738,             0.00066259,             0.00066259,             0.00066259
                      6,                0.89331,                0.65167,                0.97722,                 1.8748,             0.00064974,             0.00064974,             0.00064974
                      7,                0.82489,                0.64444,                  0.975,                 1.8873,             0.00063689,             0.00063689,             0.00063689
                      8,                0.76499,                0.64556,                0.97556,                 1.8769,             0.00062404,             0.00062404,             0.00062404
                      9,                0.72098,                  0.645,                0.97056,                 1.8669,             0.00061118,             0.00061118,             0.00061118
                     10,                0.67172,                0.64944,                0.97333,                 1.8534,             0.00059833,             0.00059833,             0.00059833
                     11,                0.61156,                0.64333,                0.97667,                   1.86,             0.00058548,             0.00058548,             0.00058548
                     12,                0.55462,                0.61778,                0.97222,                 1.8687,             0.00057263,             0.00057263,             0.00057263
                     13,                0.51562,                0.61222,                0.97389,                 1.8803,             0.00055978,             0.00055978,             0.00055978
                     14,                0.46127,                0.63167,                0.97333,                 1.8574,             0.00054692,             0.00054692,             0.00054692
                     15,                0.43504,                0.62889,                0.97056,                 1.8594,             0.00053407,             0.00053407,             0.00053407
                     16,                0.40157,                0.60278,                0.97556,                 1.8804,             0.00052122,             0.00052122,             0.00052122
                     17,                0.38621,                  0.625,                0.97944,                 1.8583,             0.00050837,             0.00050837,             0.00050837
                     18,                0.33694,                   0.64,                0.97167,                 1.8472,             0.00049552,             0.00049552,             0.00049552
                     19,                0.30719,                0.63889,                0.96889,                 1.8406,             0.00048266,             0.00048266,             0.00048266
                     20,                0.28587,                0.62389,                0.97222,                 1.8468,             0.00046981,             0.00046981,             0.00046981
